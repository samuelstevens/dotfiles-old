#!/usr/bin/env bash

set -e

WIKI_DIR="$HOME/Documents/wiki"
LINK_DIR="$WIKI_DIR/.links"

function print_usage {
    echo "wiki 0.3.1"
    echo "Samuel Stevens <samuel.robert.stevens@gmail.com>"
    echo "A simple wiki."
    echo
    echo "USAGE:"
    echo "  wiki [COMMAND]"
    echo
    echo "The wiki is a flat directory with no hierarchy. Files contain tags starting with #. To find files, use 'find'."
    echo
    echo "COMMANDS"
    echo "  find WORD [WORD ...]  Find all files matching each of the words."
    echo "                        If there is only one matching file, opens it directly."
    echo "  new WORD [WORD ...]   Make a new file with the phrase."
    echo "  tags                  Show all # tags in your wiki with a count."
    echo "  recent                Show a list of the most recent articles edited."
}


function wiki_find {
    shift  # gets rid of "find" in $1

    # set up the $file variable
    if [ "$1" = "" ]; then
        file=$(fd --type file --maxdepth 1 | fzf)
    else
        files=$(fd . | sed 's|\./||')

        for pattern in "$@"; do
            files=$(rg "$pattern" $files --files-with-matches | sort | uniq)
        done
        
        if [ "$files" = "" ]; then
            echo "No files found matching '$@'."
            exit 1
        elif [ $(echo $files | wc -w | xargs) -eq 1 ]; then
            file=$files
        else
            file=$(echo $files | tr ' ' '\n' | fzf)
        fi

    fi

    if [ "$file" = "" ]; then
        echo "No file selected!"
    else
        wiki_start $file
    fi
}

function wiki_new {
    shift # gets rid of "new"

    # File name is the args joined with a dash.
    # First line is the args preceded by '# '

    filename="$(echo "$@" | sed 's/ /-/g' | tr A-Z a-z).md"
    title="# ${@^}" # Every word now starts with a capital letter.
    echo $title > $filename
    wiki_start $filename
}

function wiki_tags {
    shift

    tag_regex='#(\w|/|-|_)+'

    rg --max-depth 1 --no-line-number --no-filename --only-matching $tag_regex | sort | uniq -c | less
}

function wiki_recent {
    shift
    file=$(ls -trh | tail | tac | fzf)
    wiki_start $file
}

function wiki_start {
    if [ "$1" = "" ]; then
        $EDITOR
    elif [ "${1#*.}" = "md" ]; then
        $EDITOR $1
    else
        echo "${1#*.}"
        open $1
    fi
    
    #             https    one or more subdomains tld      optional / and some junk
    url_regex="\b(https?://((:?[A-Za-z0-9\-_]+\.)+[A-Za-z]+(:?/[A-Za-z0-9%\-_/.]*))?)\b"
    url_regex="\b(https?://((:?[A-Za-z0-9\-_]+\.)+[A-Za-z]+(:?/[^)]*))?)\b"
    # Check for all links in the wiki. Download them.
    links_and_names=$(rg --only-matching --no-filename --no-line-number $url_regex --replace '$1*$2' --max-depth=1 .)  # using a * because I don't know how to write good bash.
    for link_and_name in $links_and_names; do
        link=$(echo $link_and_name | cut -d '*' -f 1)
        name=$(echo $link_and_name | cut -d '*' -f 2 | tr '/' '-')
        name=${name%-}  # removes trailing dash

        if [ "$name" = "" ]; then
            continue
        fi

        target="$LINK_DIR/$name.html"

        if [ ! -f $target ]; then
            echo "download $link to $target"
            if [ ! $(monolith $link --isolate --no-audio --no-frames --no-video --unwrap-noscript --output "$target" --silent) ]; then
                echo $?
                echo "Failed to download $link to $target"
            fi
        fi
    done
}

function wiki_main {
    if [ "$1" = "" ]; then
        wiki_start
    else 
        case "$1" in
            start) wiki_start ;;
            find) wiki_find $@ ;;
            new) wiki_new $@ ;;
            tags) wiki_tags $@ ;;
            recent) wiki_recent $@ ;; 
            *) print_usage; exit 1;;
        esac
    fi
}

mkdir -p "$WIKI_DIR"
mkdir -p "$LINK_DIR"
cd $WIKI_DIR

require "rg"
require "fd"
require "fzf"
require "monolith"

wiki_main "$@"
